---
title: "Banknoten"
author: "JoKeYa"
date: "08/05/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ddalpha)
library(ggplot2)
library(randomForest)
library(caret)
library(pROC)
library(mlbench)

##In der eigenen Umgebung ben√∂tigt man:
#install.packages("ddalpha")
#install.packages("ggplot2")
#install.packages("randomForest")
#install.packages("pROC")
#install.packages("e1071")
```


## Setup
Als Library wurde ddalpha verwendet.
Als Datenset verwenden wir Banknoten.
```{r get_data}
data("banknoten")
data("iris")
plot(banknoten, col = banknoten$falsch)
```

Da die Klassifikation ein Integer ist, kann es wie oben vorkommen, dass der Wert nicht korrekt interpretiert werden kann.
Somit muss die Klassifikation zu einem Faktor √ºbersetzt werden.
```{r set_factor}
banknoten$faktor <- as.factor(banknoten$falsch)
plot(banknoten, col = banknoten$faktor)
```
L√§nge: L√§nge der Banknote
Links: H√∂he der Banknote bei der linken Seite
Rechts: H√∂he der Banknote bei der rechten Seite
Oben: Distanz zwischen inneren Bereich und oberen Rand
Unten: Distanz zwischen inneren Bereich und unteren Rand
Diagonal: Diagonale L√§nge der Banknote

## Load and visualise the data 


```{r banknoten}
head(banknoten)

##F√ºr ROC beibehalten (Ist leider nicht ganz perfekt 1, aber dient zur Anschauung)
beispielRoc <- roc(banknoten$falsch, banknoten$diagonal)

str(banknoten)

```

Get help from google to understand what is meant by sepal/petal length and width. 

An excellent introduction in plotting data using iris data 
is available on the site: 
https://www.kaggle.com/antoniolopez/iris-data-visualization-with-r

```{r means, quantils etc}

colMeans(banknoten[,1:7])

median(banknoten$laenge)
median(banknoten$links)
median(banknoten$rechts)
median(banknoten$unten)
median(banknoten$oben)
median(banknoten$diagonal)
median(banknoten$falsch)


# The following command will give the 25% Quantile for Sepal.Length
quantile(banknoten$diagonal, 0.25)

```

I plot the data for the predictor Petal.Length as an example.
And I add the information for the mean (red line), the median (green line) and 25% / 75% quantile (blue and yellow line) in the same plot


Banknoten$falsch wird nicht mehr ben√∂tigt und kann die Statistik √ºber den Haufen werfne.
Somit wurde es meinerseits entfernt.
```{r removeFalsch}

banknoten$falsch = NULL

```

```{r, plot faktor}

ggplot(banknoten, aes(x=diagonal, colour=faktor, fill=faktor)) +
  geom_density(alpha=.3) +
  geom_vline(aes(xintercept=mean(diagonal,
                 colour=faktor)), color="red", size=1) +
  geom_vline(aes(xintercept=median(diagonal,
                 colour=faktor)), color="green", size=1) +
  geom_vline(aes(xintercept=quantile(diagonal, 0.25),
                 colour=faktor), color="blue", size=1) +
  geom_vline(aes(xintercept=quantile(diagonal, 0.75),
                 colour=faktor), color="yellow", size=1) +
  xlab("Links") +  
  ylab("Menge") +
  theme(legend.position="none")
  
```


## Partition the data in training and test sets

```{r partition}
#set.seed to ensure reproducability


#Entfernen der Daten, damit Prediktor nicht 100% zur√ºckgibt. -- START
banknoten$diagonal = NULL
banknoten$unten = NULL
banknoten$rechts = NULL
banknoten$oben = NULL

ggplot(banknoten, aes(x=links, colour=faktor, fill=faktor)) +
  geom_density(alpha=.3) +
  geom_vline(aes(xintercept=mean(links,
                 colour=faktor)), color="red", size=1) +
  geom_vline(aes(xintercept=median(links,
                 colour=faktor)), color="green", size=1) +
  geom_vline(aes(xintercept=quantile(links, 0.25),
                 colour=faktor), color="blue", size=1) +
  geom_vline(aes(xintercept=quantile(links, 0.75),
                 colour=faktor), color="yellow", size=1) +
  xlab("Diagonale") +  
  ylab("Faktor") +
  theme(legend.position="none")
#Entfernen der Daten, damit Prediktor nicht 100% zur√ºckgibt. -- ENDE

set.seed(13) 
trainIndex <- createDataPartition(banknoten$faktor, p = .6, 
                                  list = FALSE, times = 1)

trainSet <- banknoten[trainIndex, ]
testSet <- banknoten[-trainIndex,]
```

Make the model and look at the result
```{r randomForest_model}


model <- randomForest(formula = faktor ~ ., data = banknoten)

model

importance(model)
```

Use the model to make a prediction on the test set 
```{r randoForest_predict}
testSet$prediction <- predict(model, testSet[,1:3])
#[,1:7] wieder setzen, wenn die 4 Eigenschaften f√ºr Pr√§diktor wieder "eingeschalten" werden.
head(testSet)

```

##Confusion matrix
Die Konfusions-Matrix stellt, wie bekannt, die True Positives, False Positives, True Negatives und False Negatives.

###Specifity
True Negatives durch alle wahren Negativen, die vorhanden sind

###Sensitivity
True Positives durch alle wahren Positiven, die vorhanden sind
```{r confusion matrix}

confusionMatrix(testSet$prediction, testSet$faktor)

plot(roc(testSet$prediction, testSet$laenge), print.auc=TRUE)
lines(beispielRoc, col="blue")

plot(roc(testSet$prediction, testSet$links), print.auc=TRUE)
lines(beispielRoc, col="blue")
#auc(testSet$prediction, testSet$links)


```

###ROC Curve
(Die blaue Linie ist leider nicht perfekt auf 1, jedoch dient sie gut zur Veranschauung, was optimal w√§re.)


Eine ROC Curve stellt f√ºr EINE dieser Werte seine entsprechende Kurve dar, wie gut diese klassifiziert werden kann.


Wie oben zu sehen ist, wird entsprechend der Importance-Tabelle grafisch ersichtlich, dass "Links" bessere Werte liefern kann, denn die AUC (Area Under the Curve) is gr√∂sser, bzw. werden weniger werte falsch eingestuft.
Wenn die ROC n√§her an der blauen Ideallinie ist, desto besser konnte es von den Desicion Trees korrekt identifiziert werden.

Dementsprechend ist beim oberen der beiden ROC die Fehlerrate h√∂her, da weniger genau gesch√§tzt werden kann, bzw. weniger Werte korrekt eingesch√§tzt werden k√∂nnen


###MeanDecreaseGini

Gini-Wichtigkeit oder mittlere Verringerung der Verunreinigung (MDI) berechnet jede Merkmalsbedeutung als die Summe ¸ber die Anzahl von Teilungen (¸ber alle B‰ume hinweg), die das Merkmal enthalten, proportional zu der Anzahl von Samples, die es aufteilt.
Ein kleinerer Gini-WErt bedeutet eine "reinerer/besserer" Ansatz die Daten optimal zu teilen.
Das MDI Model nimmt immer den besten/reinsten Datensatz

###Variable Importance
```{r Variable Importance}
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

model <- train(falsch~.,data = banknoten, method="lvq", preProcess="scale",trControl=control)


importance <- varImp(model, scale=FALSE)

print(importance)

plot(importance)
```

