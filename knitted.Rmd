---
title: "Banknoten"
author: "JoKeYa"
date: "08/05/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ddalpha)
library(ggplot2)
library(randomForest)
library(caret)
library(pROC)

##In der eigenen Umgebung benötigt man:
#install.packages("ddalpha")
#install.packages("ggplot2")
#install.packages("randomForest")
#install.packages("pROC")
#install.packages("e1071")
```


## Setup
Als Library wurde ddalpha verwendet.
Als Datenset verwenden wir Banknoten.
```{r get_data}
data("banknoten")
data("iris")
plot(banknoten, col = banknoten$falsch)
```

Da die Klassifikation ein Integer ist, kann es wie oben vorkommen, dass der Wert nicht korrekt interpretiert werden kann.
Somit muss die Klassifikation zu einem Faktor übersetzt werden.
```{r set_factor}
banknoten$faktor <- as.factor(banknoten$falsch)
plot(banknoten, col = banknoten$faktor)
```
Länge: Länge der Banknote
Links: Höhe der Banknote bei der linken Seite
Rechts: Höhe der Banknote bei der rechten Seite
Oben: Distanz zwischen inneren Bereich und oberen Rand
Unten: Distanz zwischen inneren Bereich und unteren Rand
Diagonal: Diagonale Länge der Banknote

## Load and visualise the data 


```{r banknoten}
head(banknoten)

##Für ROC beibehalten (Ist leider nicht ganz perfekt 1, aber dient zur Anschauung)
beispielRoc <- roc(banknoten$falsch, banknoten$diagonal)

str(banknoten)

```

Get help from google to understand what is meant by sepal/petal length and width. 

An excellent introduction in plotting data using iris data 
is available on the site: 
https://www.kaggle.com/antoniolopez/iris-data-visualization-with-r

```{r means, quantils etc}

colMeans(banknoten[,1:7])

median(banknoten$laenge)
median(banknoten$links)
median(banknoten$rechts)
median(banknoten$unten)
median(banknoten$oben)
median(banknoten$diagonal)
median(banknoten$falsch)


# The following command will give the 25% Quantile for Sepal.Length
quantile(banknoten$diagonal, 0.25)

```

I plot the data for the predictor Petal.Length as an example.
And I add the information for the mean (red line), the median (green line) and 25% / 75% quantile (blue and yellow line) in the same plot


Banknoten$falsch wird nicht mehr benötigt und kann die Statistik über den Haufen werfne.
Somit wurde es meinerseits entfernt.
```{r removeFalsch}

banknoten$falsch = NULL

```

```{r, plot faktor}

ggplot(banknoten, aes(x=diagonal, colour=faktor, fill=faktor)) +
  geom_density(alpha=.3) +
  geom_vline(aes(xintercept=mean(diagonal,
                 colour=faktor)), color="red", size=1) +
  geom_vline(aes(xintercept=median(diagonal,
                 colour=faktor)), color="green", size=1) +
  geom_vline(aes(xintercept=quantile(diagonal, 0.25),
                 colour=faktor), color="blue", size=1) +
  geom_vline(aes(xintercept=quantile(diagonal, 0.75),
                 colour=faktor), color="yellow", size=1) +
  xlab("Links") +  
  ylab("Menge") +
  theme(legend.position="none")
  
```


## Partition the data in training and test sets

```{r partition}
#set.seed to ensure reproducability


#Entfernen der Daten, damit Prediktor nicht 100% zurückgibt. -- START
banknoten$diagonal = NULL
banknoten$unten = NULL
banknoten$rechts = NULL
banknoten$oben = NULL

ggplot(banknoten, aes(x=links, colour=faktor, fill=faktor)) +
  geom_density(alpha=.3) +
  geom_vline(aes(xintercept=mean(links,
                 colour=faktor)), color="red", size=1) +
  geom_vline(aes(xintercept=median(links,
                 colour=faktor)), color="green", size=1) +
  geom_vline(aes(xintercept=quantile(links, 0.25),
                 colour=faktor), color="blue", size=1) +
  geom_vline(aes(xintercept=quantile(links, 0.75),
                 colour=faktor), color="yellow", size=1) +
  xlab("Diagonale") +  
  ylab("Faktor") +
  theme(legend.position="none")
#Entfernen der Daten, damit Prediktor nicht 100% zurückgibt. -- ENDE

set.seed(13) 
trainIndex <- createDataPartition(banknoten$faktor, p = .6, 
                                  list = FALSE, times = 1)

trainSet <- banknoten[trainIndex, ]
testSet <- banknoten[-trainIndex,]
```

Make the model and look at the result
```{r randomForest_model}


model <- randomForest(formula = faktor ~ ., data = banknoten)

model

importance(model)
```

Use the model to make a prediction on the test set 
```{r randoForest_predict}
testSet$prediction <- predict(model, testSet[,1:3])
#[,1:7] wieder setzen, wenn die 4 Eigenschaften für Prädiktor wieder "eingeschalten" werden.
head(testSet)

```

##Confusion matrix
Die Konfusions-Matrix stellt, wie bekannt, die True Positives, False Positives, True Negatives und False Negatives.

###Specifity
True Negatives durch alle wahren Negativen, die vorhanden sind

###Sensitivity
True Positives durch alle wahren Positiven, die vorhanden sind
```{r confusion matrix}

confusionMatrix(testSet$prediction, testSet$faktor)

plot(roc(testSet$prediction, testSet$laenge), print.auc=TRUE)
lines(beispielRoc, col="blue")

plot(roc(testSet$prediction, testSet$links), print.auc=TRUE)
lines(beispielRoc, col="blue")
#auc(testSet$prediction, testSet$links)


```

###ROC Curve
(Die blaue Linie ist leider nicht perfekt auf 1, jedoch dient sie gut zur Veranschauung, was optimal wäre.)


Eine ROC Curve stellt für EINE dieser Werte seine entsprechende Kurve dar, wie gut diese klassifiziert werden kann.


Wie oben zu sehen ist, wird entsprechend der Importance-Tabelle grafisch ersichtlich, dass "Links" bessere Werte liefern kann, denn die AUC (Area Under the Curve) is grösser, bzw. werden weniger werte falsch eingestuft.
Wenn die ROC näher an der blauen Ideallinie ist, desto besser konnte es von den Desicion Trees korrekt identifiziert werden.

Dementsprechend ist beim oberen der beiden ROC die Fehlerrate höher, da weniger genau geschätzt werden kann, bzw. weniger Werte korrekt eingeschätzt werden können
