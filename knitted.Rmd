---
title: "Banknoten"
author: "JoKeYa"
date: "12/06/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ddalpha)
library(ggplot2)
library(randomForest)
library(caret)
library(pROC)
library(mlbench)

##In der eigenen Umgebung benötigt man:
#install.packages("ddalpha")
#install.packages("ggplot2")
#install.packages("randomForest")
#install.packages("pROC")
#install.packages("e1071")
#install.packages("mlbench")
```


## Setup
Als Library wurde ddalpha verwendet.
Als Datenset verwenden wir Banknoten.
```{r get_data}
data("banknoten")
plot(banknoten, col = banknoten$falsch)
```

Da die Klassifikation ein Integer ist, kann es wie oben vorkommen, dass der Wert nicht korrekt interpretiert werden kann.
Somit muss die Klassifikation zu einem Faktor übersetzt werden.
```{r set_factor}
banknoten$faktor <- as.factor(banknoten$falsch)
plot(banknoten, col = banknoten$faktor)
```

Länge: Länge der Banknote

Links: Höhe der Banknote bei der linken Seite

Rechts: Höhe der Banknote bei der rechten Seite

Oben: Distanz zwischen inneren Bereich und oberen Rand

Unten: Distanz zwischen inneren Bereich und unteren Rand

Diagonal: Diagonale Länge der Banknote


## Visualisierung bestehender Daten
```{r banknoten}
head(banknoten)

##Für ROC beibehalten (Ist leider nicht ganz perfekt 1, aber dient zur Anschauung)
beispielRoc <- roc(banknoten$falsch, banknoten$diagonal)

str(banknoten)

colMeans(banknoten[,1:7])

median(banknoten$laenge)
median(banknoten$links)
median(banknoten$rechts)
median(banknoten$unten)
median(banknoten$oben)
median(banknoten$diagonal)
median(banknoten$falsch)

quantile(banknoten$diagonal, 0.25)
```

Banknoten$falsch wird nicht mehr benötigt und kann die Statistik über den Haufen werfen.
Somit wurde es anbei entfernt.
```{r removeFalsch}
banknoten$falsch = NULL
```

## Definierung der Daten
Bildlich dargestellt wird anbei die Diagonale des Datensets geplottet mit der Unterscheidung von dem Faktor.

Man sieht sehr gut, dass die Daten fast perfekt voneinander getrennt werden können und dementsprechend die Decision Trees ein perfektes Ergebnis eruieren können.
```{r, plot faktor}
ggplot(banknoten, aes(x=diagonal, colour=faktor, fill=faktor)) +
  geom_density(alpha=.3) +
  geom_vline(aes(xintercept=mean(diagonal,
                 colour=faktor)), color="red", size=1) +
  geom_vline(aes(xintercept=median(diagonal,
                 colour=faktor)), color="green", size=1) +
  geom_vline(aes(xintercept=quantile(diagonal, 0.25),
                 colour=faktor), color="blue", size=1) +
  geom_vline(aes(xintercept=quantile(diagonal, 0.75),
                 colour=faktor), color="yellow", size=1) +
  xlab("Links") +  
  ylab("Menge") +
  theme(legend.position="none")
```

Deswegen haben wir uns entschieden die "besten" Datensätze zu entfernen, damit wir überhaupt Fehlerquellen erhalten.

### Wichtigkeit der Variablen (MeanDecreaseGini)
```{r MeanDecreaseGini}
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
banknoten.rf <- randomForest(faktor ~ ., data = banknoten, ntree=1000, keep.forest=FALSE, importance=TRUE)

varImp(banknoten.rf)
varImpPlot(banknoten.rf)
```

Da diagonal, Unten, Rechts und Oben die wichtigsten 4 Datensätze sind, werden sie entfernt.

Jetzt ist es nicht mehr so eindeutig, bzw. sind die wahren von den falschen Werten weniger gut zu unterscheiden.

```{r plot faktor 2}
banknoten$diagonal = NULL
banknoten$unten = NULL
banknoten$rechts = NULL
banknoten$oben = NULL

ggplot(banknoten, aes(x=links, colour=faktor, fill=faktor)) +
  geom_density(alpha=.3) +
  geom_vline(aes(xintercept=mean(links,
                 colour=faktor)), color="red", size=1) +
  geom_vline(aes(xintercept=median(links,
                 colour=faktor)), color="green", size=1) +
  geom_vline(aes(xintercept=quantile(links, 0.25),
                 colour=faktor), color="blue", size=1) +
  geom_vline(aes(xintercept=quantile(links, 0.75),
                 colour=faktor), color="yellow", size=1) +
  xlab("Links") +  
  ylab("Faktor") +
  theme(legend.position="none")
```

## Erstellung des Training- und Testsets
Der ganze Bestand wird in die zwei Sets eingeteilt und das Trainingset erhält bereits via RandomForest seine Prädiktion erhalten.

Die zwei Spalten sind nun dmentsprechend mehr Wert als vorhin.
```{r raining- and teststet}
set.seed(13) 
trainIndex <- createDataPartition(banknoten$faktor, p = .6, 
                                  list = FALSE, times = 1)

trainSet <- banknoten[trainIndex, ]
testSet <- banknoten[-trainIndex,]

model <- randomForest(formula = faktor ~ ., data = banknoten)

testSet$prediction <- predict(model, testSet[,1:3])

importance(model)
```

### Confusion matrix
Die Konfusions-Matrix stellt, wie bekannt, die True Positives, False Positives, True Negatives und False Negatives.

#### Specifity
True Negatives durch alle wahren Negativen, die vorhanden sind

#### Sensitivity
True Positives durch alle wahren Positiven, die vorhanden sind
```{r confusion matrix}
confusionMatrix(testSet$prediction, testSet$faktor)
```

### ROC Curve
(Die blaue Linie ist leider nicht perfekt auf 1, jedoch dient sie gut zur Veranschauung, was optimal wäre.)

Eine ROC Curve stellt für EINE dieser Werte seine entsprechende Kurve dar, wie gut diese klassifiziert werden kann.

Wie oben zu sehen ist, wird entsprechend der Importance-Tabelle grafisch ersichtlich, dass "Links" bessere Werte liefern kann, denn die AUC (Area Under the Curve) is grösser, bzw. werden weniger werte falsch eingestuft.
Wenn die ROC näher an der blauen Ideallinie ist, desto besser konnte es von den Desicion Trees korrekt identifiziert werden.

Dementsprechend ist beim oberen der beiden ROC die Fehlerrate höher, da weniger genau geschätzt werden kann, bzw. weniger Werte korrekt eingeschätzt werden können
```{r roc}
plot(roc(testSet$prediction, testSet$laenge), print.auc=TRUE)
lines(beispielRoc, col="blue")

plot(roc(testSet$prediction, testSet$links), print.auc=TRUE)
lines(beispielRoc, col="blue")
```

## Out-of-Bag Error
Zu Beginn teilt man das Dataset in Trainings-Daten und Test-Daten auf. Mit den Trainings-Daten wird der Algorithmus trainiert. Wird nun der trainierte Algorithmus auf die Test-Daten angewendet, so erhalten wir eine mögliche Fehlerrate bei der Kategorisierung. Diese Fehlerrate nennt man Out-of-Bag Error, und ist eine Schätzung wie genau der Algorithmus ist.


## Tuning
Hier sieht man, dass über das Tuning herauskommt, dass mtry mit Nummer 1 unsere beste Hoffnung ist.

Es wird hier nur ein false Positive "verbessert", jedoch ist es ein kleines Set und somit schon super.

```{r tuning}
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(13)
tunegrid <- expand.grid(.mtry=c(1:3))
rf_gridsearch <- train(faktor ~., data=testSet, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
print(rf_gridsearch)
plot(rf_gridsearch)

model <- randomForest(formula = faktor ~ ., data = banknoten, mtry=1)
testSet$prediction <- predict(model, testSet[,1:3])
confusionMatrix(testSet$prediction, testSet$faktor)

model <- randomForest(formula = faktor ~ ., data = banknoten, mtry=3)
testSet$prediction <- predict(model, testSet[,1:3])
confusionMatrix(testSet$prediction, testSet$faktor)
```
